{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的保存和读取 笔记\n",
    "教程视频链接：https://www.bilibili.com/video/BV1hE411t7RN\n",
    "\n",
    "这篇笔记对应视频合集中的\n",
    "- 网络模型的保存和读取\n",
    "\n",
    "pytorch提供了保存训练结果的方法。我们既可以保存完整的神经网络数据，也可以只保存模型参数而不保存神经网络结构（推荐的保存方式）。这两种保存方式得到的模型文件，其加载方式也有所不同，下面举例进行介绍：\n",
    "\n",
    "### 对比两种保存方式：\n",
    "\n",
    "| Feature                                  | `torch.save(vgg16, 'vgg16_method.pth')`               | `torch.save(vgg16.state_dict(), 'vgg16_method2.pth')`  |\n",
    "|------------------------------------------|--------------------------------------------------------|--------------------------------------------------------|\n",
    "| **What is saved?**                       | Entire model object (architecture + weights)           | Only the model weights (state_dict)                     |\n",
    "| **Requires class definition during load?** | Yes, you need the class definition to reload it        | Yes, but only the class definition, not the full model |\n",
    "| **Size of the saved file**               | Larger, because it saves the entire model object       | Smaller, since it only saves the model's weights        |\n",
    "| **Flexibility (to change the architecture)** | Less flexible (requires exact same class definition)   | More flexible (can load weights into any compatible model) |\n",
    "\n",
    "\n",
    "## 1.模型的保存\n",
    "模型的保存使用`torch.save`方法，保存的文件格式为`.pth`，这样会同时保存模型的网络结构和模型的权重参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "vgg16 = torchvision.models.vgg16(weights=None)\n",
    "torch.save(vgg16, 'vgg16_method.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种保存方式（推荐方式）是把网络模型的参数保存为python字典，同样是以`.pth`格式保存。这种保存方式仅保存模型参数而不保存网络结构，因而占用的空间较小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'vgg16_method2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.模型的加载\n",
    "模型的加载使用`torch.load`类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('vgg16_method.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载仅保存参数的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取保存的字典\n",
    "dic = torch.load('vgg16_method2.pth')\n",
    "\n",
    "#将字典中的参数加载到网络里\n",
    "vgg16 = torchvision.models.vgg16(weights=None)\n",
    "vgg16.load_state_dict(state_dict=dic)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.常见问题\n",
    "\n",
    "在老版本pytorch中，若加载的神经网络是自定义的神经网络类的实例，需要把该类的定义包含在脚本里（拷贝或import）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tudui(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=5)\n",
    "tudui = Tudui()\n",
    "\n",
    "torch.save(tudui, 'tudui_method.pth')\n",
    "\n",
    "#在另一个文件中\n",
    "class Tudui(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=5)\n",
    "\n",
    "model = torch.load('tudui_method.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch250115",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
